{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Modeling - Example Project\n",
    "\n",
    "This project uses everything we've learned about Time Series Analysis to forecast the median home sales price by zipcode across the United States. Comments have been added to the code to explain what is happening at each step. \n",
    "\n",
    "### (Private--Do not release to students)\n",
    "\n",
    "## Step 1: Import Necessary Packages\n",
    "\n",
    "Needed for this lab:\n",
    "\n",
    "* pandas, numpy, matplotlib for the normal stuff\n",
    "* ARIMA model from statsmodels\n",
    "* Helper functions from statsmodels, for plotting Time Series (optional)\n",
    "* TQDM, for visualizing progress bars for long runtimes (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load and Inspect Data\n",
    "\n",
    "Load data directly from `zillow_data.csv`. Cast `'RegionName'` column to `str` during loading process. \n",
    "\n",
    "\n",
    "## A Note on Null Values\n",
    "\n",
    "This dataset contains missing values. There are three possible cases for null values in this dataset:\n",
    "\n",
    "1. A sequence of missing values at the start of the time series. This is seen with newer zipcodes, which will have missing values for any date before the creation of that zipcode. \n",
    "2. A sequence of missing values at the end of the time series. This is seen with zipcodes that were dissolved after a rezoning. \n",
    "3. Spontaneous missing values, with no pattern. These are just run-of-the-mill missing values.\n",
    "\n",
    "Only null values of type '3' can be imputed safely. Please note that this is not done in this example notebook--instead, all zipcodes with any missing values are simply dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect the data\n",
    "raw_data_df = pd.read_csv('zillow_data.csv', dtype={'RegionName': 'str'})\n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Drop Unneeded Columns\n",
    "\n",
    "We don't need `'SizeRank'` or `'RegionID'`, so let's drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = raw_data_df.drop(['SizeRank', 'RegionID'], axis=1, inplace=False)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Filtering Zipcodes for Arkansas\n",
    "\n",
    "Zipcodes were retrieved by searching city zipcodes on Google. Store each as a string inside separate lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zipcodes for AK metro areas\n",
    "hot_springs = ['71901', '71902', '71903', '71913', '71914']\n",
    "little_rock = ['72002', '72203', '72207', '72212', '72219', '72225', '72260', '72103', \n",
    "               '72204', '72209', '72214', '72221', '72227', '72295', '72201', '72205', \n",
    "               '72210', '72215', '72222', '72231', '72202', '72206', '72211', '72217', \n",
    "               '72223', '72255']\n",
    "fayetteville = ['72701', '72702', '72703', '72704', '72730', '72764']\n",
    "searcy = ['72082', '72143', '72145', '72149']\n",
    "\n",
    "ar_city_zipcodes = hot_springs + little_rock + fayetteville + searcy\n",
    "\n",
    "ar_city_zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_cities_df = df1[df1['RegionName'].isin(ar_city_zipcodes)]\n",
    "ar_cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Filtering by City Name\n",
    "\n",
    "Can also get zipcodes for a given city by filtering by the name of the city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that zipcodes starting with 0 are now formatted correctly\n",
    "df1[df1['City'] == 'Agawam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Creating Time Series Plots\n",
    "\n",
    "## Step 4.1: Filter by Zipcodes\n",
    "\n",
    "In this example, we slice the relevant zipcodes for each of our example cities into separate DataFrames. This will make visualizing them easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data sets containing zip codes for AR metro area\n",
    "searcy_df = df1[df1['RegionName'].isin(searcy)]\n",
    "littlerock_df = df1[df1['RegionName'].isin(little_rock)]\n",
    "fayetteville_df = df1[df1['RegionName'].isin(fayetteville)]\n",
    "hotsprings_df = df1[df1['RegionName'].isin(hot_springs)]\n",
    "\n",
    "display(searcy_df)\n",
    "display(littlerock_df)\n",
    "display(fayetteville_df)\n",
    "display(hotsprings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.2: Remove Unneeded Columns\n",
    "\n",
    "For our Time Series Plots, we only need the `RegionName` and the actual median housing values for each.  This means that we can drop everything else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['City', 'State', 'Metro', 'CountyName']\n",
    "searcy_clean_df = searcy_df.drop(cols_to_drop, axis=1, inplace=False)\n",
    "fayetteville_clean_df = fayetteville_df.drop(cols_to_drop, axis=1, inplace=False)\n",
    "hotsprings_clean_df = hotsprings_df.drop(cols_to_drop, axis=1, inplace=False)\n",
    "littlerock_clean_df = littlerock_df.drop(cols_to_drop, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.3: Get Datetimes\n",
    "\n",
    "We will use the datetimes as our indices for these plots. Currently, the column names for each remaining column that is not the zipcode in question is contains the datetimes. These datetimes are stored as strings, in the format `'%Y-%m'`. \n",
    "\n",
    "In the cell below, we create a series called `datetimes` using pandas and the column values for one of the cities (we exclude the first column value, since this contains `'RegionName'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = pd.to_datetime(searcy_clean_df.columns.values[1:], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.4: Set Params for Matplotlib Visualizations\n",
    "\n",
    "This step is optional, but will make our plots easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.5: Create a Function for Visualizing Time Series Data\n",
    "\n",
    "This one is a bit complicated, so the code is commented and broken down line by line. \n",
    "\n",
    "**_NOTE_**: For the example below, we've only visualized the data for 1997 through 2013. This was done on purpose, to show how to visualize select ranges of data. The index values were obtained by manually looking at the date ranges and determining that `[10:215]` includes everything between 1997 and 2013. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_series(df, name=None, legend=None):\n",
    "    \n",
    "    # Instantiate a figure object. \n",
    "    plt.figure()\n",
    "    if not legend:\n",
    "        legend = list(df['RegionName'])\n",
    "    # Enumerate through each row in the dataframe passed in. Each row is a different zipcode.\n",
    "    for ind, row in df.iterrows():\n",
    "        \n",
    "        # Get the median housing value data for the date ranges we want and store in a Series object\n",
    "        data = pd.Series(row.iloc[10:215])\n",
    "        # Set the appropriate datetimes for data as the index for our data series\n",
    "        data.index = datetimes[10:215]\n",
    "        # Plot data for current zipcode on figure we instantiated on line 4. Set xticks to corresponding datetimes\n",
    "        # Also make the figure large, so that we can read it more easily\n",
    "        ax = data.plot(figsize=(20, 10), xticks=datetimes[10:215])\n",
    "        # add a label\n",
    "        plt.ylabel(\"Median Sales Value ($)\")\n",
    "        # let matplootlib autoformat the datetimes for the xticks\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        \n",
    "        # If name of city was provided, use it to set title of plot\n",
    "        if name:\n",
    "            plt.title(\"Median Home Value by Zip Code in {} from 1997-2013\".format(name))\n",
    "        else:\n",
    "            plt.title(\"Avg Median Home Value in AR Metro Area, 1997-2013\")\n",
    "        \n",
    "    plt.legend(legend)\n",
    "            \n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "time_series(fayetteville_clean_df, name='Fayetteville', legend=fayetteville)\n",
    "# time_series(searcy_clean_df, name='Searcy')\n",
    "# time_series(hotsprings_clean_df, hot_springs, 'Hot Springs')\n",
    "# time_series(littlerock_clean_df, little_rock, 'Little Rock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.6: Visualizing the Average Median Home Sale Price for a Collection of Zipcodes\n",
    "\n",
    "To visualize the average median home sales value for an area, we can use the function we created above, but we need to do a bit of processing first to get it into the shape needed. \n",
    "\n",
    "1. First, we concatenate all of the dataframes containing the zipcodes we want to average.\n",
    "2. Next, we create a new DataFrame containing a single column of data called `'Avg_Median_Value'` for the date range we want (in this example, still focusing only on values between 1997-2013). \n",
    "3. Next, drop the `'RegionName'` column.\n",
    "4. Finally, inspect the data to see what our newly computed `'Avg_Median_Value'` data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arkansas_metro_df = pd.concat([searcy_clean_df, littlerock_clean_df, fayetteville_clean_df, hotsprings_clean_df])\n",
    "avg_metro_value_df = pd.DataFrame(arkansas_metro_df[10:215].mean(), columns=['Avg_Median_Value'])\n",
    "avg_metro_value_df.drop('RegionName', axis=0, inplace=True)\n",
    "avg_metro_value_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks fine, but it need to be transposed in order to work with the function we've written. \n",
    "\n",
    "Note that we can chance the value of our legend to whatever string we want by wrapping it in an array and passing it in to the `legend` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series(avg_metro_value_df.transpose(), name=\"Average Median Value\", legend=['Avg Median Sale Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Modeling \n",
    "\n",
    "The next section demonstrates how to do ARIMA modeling on this data set. \n",
    "\n",
    "## 'Melting' the Data\n",
    "\n",
    "In order to train the model, we need to first **_melt_** the data into the appropriate shape. ARIMA models expect the data in columnar format (\"long\"), and in our current format, the values are stored in rows (\"wide\"). \n",
    "\n",
    "The cell below shows some sample code for melting a dataframe, and displays the same dataframe in both wide (unmelted) and long (melted) formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = pd.melt(searcy_df, id_vars=['RegionName', 'City', 'State', 'Metro', 'CountyName'], var_name='time')\n",
    "melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "melted = melted.dropna(subset=['value'])\n",
    "\n",
    "display(searcy_df.head())\n",
    "melted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Create a Function for Melting Data\n",
    "\n",
    "Since this is an operation we'll need to for any group of data we want to format for ARIMA modeling, we should create a function in order to save ourselves some time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def melt_data(df):\n",
    "    melted = pd.melt(df, id_vars=['RegionName', 'City', 'State', 'Metro', 'CountyName'], var_name='time')\n",
    "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    return melted.groupby('time').aggregate({'value':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Creating a Function to Evaluate Results\n",
    "\n",
    "Before we actually fit the model, we'll create a function that creates predictions for datetimes with known values based on the previous data, and then compare the lagged predictions with ground truth values from our time series data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df, preds, name):\n",
    "    if 'pandas.core.frame.DataFrame' in str(type(df)):\n",
    "        current_price = df.iloc[-1].value\n",
    "    else:\n",
    "        current_price = df[-1]\n",
    "    year_later = preds[11]\n",
    "    year_3_val = preds[35]\n",
    "    year_5_val = preds[-1]\n",
    "\n",
    "    print(\"Current Avg Median Home Value in {}: ${:.2f}\".format(name, current_price))\n",
    "    print(\"Predicted Avg Median Home Value for {} in April 2019: ${:.2f}\".format(name, year_later))\n",
    "    expected_appreciation_value_1 = year_later - current_price\n",
    "    expected_appreciation_percent_1 = expected_appreciation_value_1 / current_price\n",
    "    expected_appreciation_value_3 = year_3_val - current_price\n",
    "    expected_appreciation_percent_3 = expected_appreciation_value_3 / current_price\n",
    "    expected_appreciation_value_5 = year_5_val - current_price\n",
    "    expected_appreciation_percent_5 = expected_appreciation_value_5 / current_price\n",
    "\n",
    "    print(\"Expected property value appreciation for 1 year in {} :  ${:.2f}\".format(name, expected_appreciation_value_1))\n",
    "    print(\"Expected Return on Investment after 1 year:  {:.4f}%\".format(expected_appreciation_percent_1 * 100))\n",
    "    print(\"Expected property value appreciation for 3 years in {} :  ${:.2f}\".format(name, expected_appreciation_value_3))\n",
    "    print(\"Expected Return on Investment after 3 years:  {:.4f}%\".format(expected_appreciation_percent_3 * 100))\n",
    "    print(\"Expected property value appreciation for 5 years in {} :  ${:.2f}\".format(name, expected_appreciation_value_5))\n",
    "    print(\"Expected Return on Investment after 5 years:  {:.4f}%\".format(expected_appreciation_percent_5 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Fitting Our ARIMA Model\n",
    "\n",
    "Finally, we create a `fit_model()` function that takes in our (melted!) dataframe, the zipcode (for display purposes), and an optional parameter for visualizing the results of our model's fit. \n",
    "\n",
    "The function below has been commented to explain what is happening at each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(df, zipcode, show_graph=True):\n",
    "    # Get only the values from the dataframe\n",
    "    vals = df.values\n",
    "    # Split the data into training and testing sets by holding out dates past a certain point. Below, we use index 261 for \n",
    "    # this split\n",
    "    train = vals[:261]\n",
    "    test = vals[261:]\n",
    "    \n",
    "    # Use a list comprehension to create a \"history\" list using our training data values\n",
    "    history = [i for i in train]\n",
    "   \n",
    "    # initialize an empty list for predictions\n",
    "    preds = []\n",
    "    \n",
    "    # loop through a list the length of our training set\n",
    "    for i in range(len(test)):\n",
    "        \n",
    "        # create an ARIMA model and pass in our history list. Also set `order=(0,1,1)` (order refers to AR and MA params--\n",
    "        # see statsmodels documentation for ARIMA for more details)\n",
    "        model = ARIMA(history, order=(0,1,1))\n",
    "        \n",
    "        # Fit the model we just created\n",
    "        fitted_model = model.fit(disp=0)\n",
    "        # Get the forecast of the next value from our fitted model, and grab the first value to use as our 'y-hat' prediction\n",
    "        output = fitted_model.forecast()\n",
    "        y_hat = output[0]\n",
    "        \n",
    "        # append y_hat to our list of predictions\n",
    "        preds.append(y_hat)\n",
    "        obs = test[i]\n",
    "        \n",
    "        # Get the actual ground truth value for this datetime and append it to the history array\n",
    "        history.append(obs)\n",
    "    \n",
    "    \n",
    "    # get the forecast for the next three years (1 month==1 timestep in our data)\n",
    "    future_preds = fitted_model.forecast(steps=36)[0]\n",
    "\n",
    "    # Visualize the ARIMA model's predictions vs the actual ground truth values for our test set\n",
    "    if show_graph == True:\n",
    "        print('Predicted: {} \\t Expected: {}'.format(y_hat, obs))\n",
    "        # Also calculate the MSE\n",
    "        mse = mean_squared_error(test, preds)\n",
    "        print(\"MSE for Test Set: {}\".format(mse))\n",
    "        plt.plot(test)\n",
    "        plt.plot(preds, color='r')\n",
    "        plt.ylabel('Median Home Value ($)')\n",
    "        plt.title('Predicted vs Expected Median Home Sale Values'.format(zipcode))\n",
    "        plt.legend(['Actual', 'Predicted'])\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(future_preds)\n",
    "        plt.ylabel('Median Home Value ($)')\n",
    "        plt.title('Predicted Home Value, {}, Next 36 Months'.format(zipcode))\n",
    "        plt.show()\n",
    "        get_results(df, future_preds, zipcode)\n",
    "        \n",
    "    return future_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df = melt_data(df1)\n",
    "aggregate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fit_model(aggregate_df, \"US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Compare Forecasts for Every Zipcode in US\n",
    "\n",
    "The following cells demonstrate how to use all the code written so far to create and compare 5-year forecasts for every zipcode in the dataset. Note that this is well outside the scope of the project!\n",
    "\n",
    "**_NOTE: Running the cells below takes >1 hour on a fast computer!_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_by_zip(df, num_top_zips=3):\n",
    "    \n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    zip_roi_12_month = {}\n",
    "    zip_roi_36_month = {}\n",
    "    zip_roi_60_month = {}\n",
    "    \n",
    "    # Get 12-month RoI for each zipcode\n",
    "    with tqdm(total=len(list(df.iterrows()))) as pbar:\n",
    "        for ind, row in df.iterrows():\n",
    "            pbar.update(1)\n",
    "            series = pd.Series(row)\n",
    "            name = series[0]\n",
    "            data = series[5:]\n",
    "\n",
    "            preds_for_zip = fit_model(data, name, show_graph=False)\n",
    "            last_val = row[-1]\n",
    "            predicted_val_12 = preds_for_zip[11]\n",
    "            predicted_val_36 = preds_for_zip[35]\n",
    "            predicted_val_60 = preds_for_zip[-1]\n",
    "            roi_12 = (predicted_val_12 - last_val) / last_val\n",
    "            roi_36 = (predicted_val_36 - last_val) / last_val\n",
    "            roi_60 = (predicted_val_60 - last_val) / last_val\n",
    "            zip_roi_12_month[name] = roi_12\n",
    "            zip_roi_36_month[name] = roi_36\n",
    "            zip_roi_60_month[name] = roi_60\n",
    "    \n",
    "    # Sort dict by values and return amount specified by optional parameter, default 3\n",
    "    sorted_by_roi_12 = sorted(zip_roi_12_month.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_by_roi_36 = sorted(zip_roi_36_month.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_by_roi_60 = sorted(zip_roi_60_month.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    return (sorted_by_roi_12[:num_top_zips], sorted_by_roi_36[:num_top_zips], sorted_by_roi_60[:num_top_zips])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(results):\n",
    "    results_12 = results[0]\n",
    "    results_36 = results[1]\n",
    "    results_60 = results[2]\n",
    "    \n",
    "    print(\"Top Zip Codes for Predicted RoI--1 Year\")\n",
    "    \n",
    "    for zipcode, roi in results_12:\n",
    "        print(\"Zipcode: {} \\t Predicted 12-month RoI: {:.6f}%\".format(zipcode, roi * 100))\n",
    "    \n",
    "    print(\"\")\n",
    "    print('-' * 60)\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"Top Zip Codes for Predicted RoI--3 Years\")\n",
    "    \n",
    "    for zipcode, roi in results_36:\n",
    "        print(\"Zipcode: {} \\t Predicted 36-month RoI: {:.6f}%\".format(zipcode, roi * 100))\n",
    "        \n",
    "    print(\"\")\n",
    "    print('-' * 60)\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"Top Zip Codes for Predicted RoI--5 Years\")\n",
    "    \n",
    "    for zipcode, roi in results_60:\n",
    "        print(\"Zipcode: {} \\t Predicted 60-month RoI: {:.6f}%\".format(zipcode, roi * 100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model on every zipcode \n",
    "# (model drops rows containing any null values)\n",
    "\n",
    "top_zips_in_us = model_data_by_zip(df1, num_top_zips=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_results(top_zips_in_us)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
